{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-06T00:08:37.053741Z",
     "start_time": "2025-10-06T00:08:37.033532Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import joblib"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T00:09:10.417509Z",
     "start_time": "2025-10-06T00:08:39.515875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt')\n",
    "except:\n",
    "    pass\n",
    "\n"
   ],
   "id": "cfd74679458bb041",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T00:10:44.509088Z",
     "start_time": "2025-10-06T00:10:44.181021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "books = pd.read_csv(\"books_cleaned.csv\")\n",
    "print(\"Category distribution:\")\n",
    "print(books[\"categories\"].value_counts().head(12))"
   ],
   "id": "824b5fb6eac7109e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category distribution:\n",
      "categories\n",
      "Fiction                      2487\n",
      "Juvenile Fiction              526\n",
      "Biography & Autobiography     382\n",
      "History                       252\n",
      "Literary Criticism            158\n",
      "Comics & Graphic Novels       150\n",
      "Philosophy                    147\n",
      "Religion                      135\n",
      "Drama                         120\n",
      "Juvenile Nonfiction           111\n",
      "Poetry                         71\n",
      "Literary Collections           68\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T14:54:11.557135Z",
     "start_time": "2025-10-06T14:54:11.055122Z"
    }
   },
   "cell_type": "code",
   "source": "books.columns",
   "id": "ffd3021ad3731e4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn13', 'isbn10', 'title', 'authors', 'categories', 'thumbnail',\n",
       "       'description', 'published_year', 'average_rating', 'num_pages',\n",
       "       'ratings_count', 'title_and_subtitle', 'tagged_description',\n",
       "       'cleaned_description', 'word_count', 'avg_word_length',\n",
       "       'unique_words_ratio', 'sentence_count', 'predicted_category',\n",
       "       'category_source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:59:51.898401Z",
     "start_time": "2025-10-06T20:59:51.444880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "category_mapping = {'Fiction' : \"Fiction\",\n",
    " 'Juvenile Fiction': \"Children's Fiction\",\n",
    " 'Biography & Autobiography': \"Nonfiction\",\n",
    " 'History': \"Nonfiction\",\n",
    " 'Literary Criticism': \"Nonfiction\",\n",
    " 'Philosophy': \"Nonfiction\",\n",
    " 'Religion': \"Nonfiction\",\n",
    " 'Comics & Graphic Novels': \"Fiction\",\n",
    " 'Drama': \"Fiction\",\n",
    " 'Juvenile Nonfiction': \"Children's Nonfiction\",\n",
    " 'Science': \"Nonfiction\",\n",
    " 'Poetry': \"Fiction\"}\n",
    "\n",
    "books[\"simple_categories\"] = books[\"categories\"].map(category_mapping)"
   ],
   "id": "5932728d72b0d7c0",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T00:11:04.060568Z",
     "start_time": "2025-10-06T00:10:49.587540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "\n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "        # Tokenize and remove stopwords\n",
    "        tokens = text.split()\n",
    "        tokens = [token for token in tokens if token not in self.stop_words and len(token) > 2]\n",
    "\n",
    "        # Lemmatize tokens\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def extract_features(self, text):\n",
    "        \"\"\"Extract stylistic features\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return {\n",
    "                'word_count': 0,\n",
    "                'avg_word_length': 0,\n",
    "                'unique_words_ratio': 0,\n",
    "                'sentence_count': 0\n",
    "            }\n",
    "\n",
    "        text = str(text)\n",
    "        words = text.split()\n",
    "        sentences = text.split('.')\n",
    "\n",
    "        features = {\n",
    "            'word_count': len(words),\n",
    "            'avg_word_length': np.mean([len(word) for word in words]) if words else 0,\n",
    "            'unique_words_ratio': len(set(words)) / len(words) if words else 0,\n",
    "            'sentence_count': len([s for s in sentences if len(s.strip()) > 0])\n",
    "        }\n",
    "\n",
    "        return features\n",
    "\n",
    "# Initialize the preprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Apply cleaning\n",
    "print(\"Cleaning descriptions...\")\n",
    "books['cleaned_description'] = books['description'].apply(preprocessor.clean_text)\n",
    "\n",
    "# Extract stylistic features\n",
    "print(\"Extracting stylistic features...\")\n",
    "style_features = books['description'].apply(preprocessor.extract_features).apply(pd.Series)\n",
    "books = pd.concat([books, style_features], axis=1)"
   ],
   "id": "5dfa7e8da05e5e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning descriptions...\n",
      "Extracting stylistic features...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T00:30:56.662239Z",
     "start_time": "2025-10-06T00:30:42.181519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AdvancedFeatureEngineer:\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
    "        self.genre_keywords = {\n",
    "            'fiction': ['novel', 'story', 'tale', 'character', 'plot', 'narrative'],\n",
    "            'nonfiction': ['history', 'biography', 'research', 'study', 'analysis', 'facts'],\n",
    "            'science': ['scientific', 'research', 'experiment', 'theory', 'data', 'study'],\n",
    "            'philosophy': ['philosophy', 'thought', 'theory', 'existential', 'moral', 'ethics'],\n",
    "            'religion': ['god', 'religious', 'faith', 'spiritual', 'bible', 'prayer'],\n",
    "            'poetry': ['poem', 'verse', 'rhyme', 'poetic', 'stanza', 'meter'],\n",
    "            'drama': ['play', 'drama', 'theater', 'act', 'scene', 'dialogue']\n",
    "        }\n",
    "\n",
    "    def extract_tfidf_features(self, texts):\n",
    "        return self.tfidf.fit_transform(texts)\n",
    "\n",
    "    def extract_keyword_features(self, text):\n",
    "        \"\"\"Features based on the presence of genre-specific keywords\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        features = {}\n",
    "\n",
    "        for genre, keywords in self.genre_keywords.items():\n",
    "            features[f'kw_{genre}'] = sum(1 for keyword in keywords if keyword in text_lower)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def extract_metadata_features(self, df):\n",
    "        \"\"\"Extract metadata-based features\"\"\"\n",
    "        features = pd.DataFrame()\n",
    "\n",
    "        # Publication year features\n",
    "        current_year = pd.Timestamp.now().year\n",
    "        features['years_since_pub'] = current_year - df['published_year']\n",
    "        features['is_recent'] = (features['years_since_pub'] <= 10).astype(int)\n",
    "\n",
    "        # Popularity features\n",
    "        features['rating_scaled'] = df['average_rating'] / 5.0\n",
    "        features['popularity'] = np.log1p(df['ratings_count'])\n",
    "\n",
    "        # Length features\n",
    "        features['pages_scaled'] = df['num_pages'] / df['num_pages'].max()\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "print(\"Feature Engineering...\")\n",
    "feature_engineer = AdvancedFeatureEngineer()\n",
    "\n",
    "# TF-IDF features\n",
    "tfidf_features = feature_engineer.extract_tfidf_features(books['cleaned_description'])\n",
    "\n",
    "# Keyword features\n",
    "keyword_features = books['cleaned_description'].apply(\n",
    "    feature_engineer.extract_keyword_features\n",
    ").apply(pd.Series)\n",
    "\n",
    "# Metadata features\n",
    "metadata_features = feature_engineer.extract_metadata_features(books)\n",
    "\n",
    "# Stylistic features\n",
    "style_features = books['description'].apply(preprocessor.extract_features).apply(pd.Series)\n",
    "\n",
    "# Combine all features\n",
    "all_features = pd.concat([\n",
    "    pd.DataFrame(tfidf_features.toarray()),\n",
    "    keyword_features,\n",
    "    metadata_features,\n",
    "    style_features\n",
    "], axis=1)\n",
    "\n",
    "# 🔥 FIX: Convert all column names to strings\n",
    "all_features.columns = all_features.columns.astype(str)\n",
    "\n",
    "# Handle NaN values\n",
    "all_features = all_features.fillna(0)\n",
    "\n",
    "print(f\"✅ Features shape: {all_features.shape}\")\n",
    "print(f\"✅ Column name types: {set(type(col) for col in all_features.columns)}\")\n"
   ],
   "id": "6d1c6ce1ff1fcff8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering...\n",
      "✅ Features shape: (6374, 5016)\n",
      "✅ Column name types: {<class 'str'>}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:17:48.187390Z",
     "start_time": "2025-10-06T19:17:39.539025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class BookClassifier:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'random_forest': RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=20,\n",
    "                random_state=42,\n",
    "                class_weight='balanced'\n",
    "            ),\n",
    "            'logistic_regression': LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                random_state=42,\n",
    "                class_weight='balanced'\n",
    "            ),\n",
    "            'lightgbm': lgb.LGBMClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                learning_rate=0.1,\n",
    "                num_leaves=31,\n",
    "                min_child_samples=20,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1,\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1,\n",
    "                verbose=-1\n",
    "            )\n",
    "        }\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.feature_selector = None\n",
    "\n",
    "    def prepare_categories(self, categories_series):\n",
    "        \"\"\"Prepare categories with smart grouping and return valid indices.\"\"\"\n",
    "        category_mapping = {\n",
    "            'Fiction': 'Fiction',\n",
    "            'Juvenile Fiction': \"Children's Fiction\",\n",
    "            'Comics & Graphic Novels': 'Fiction',\n",
    "            'Drama': 'Fiction',\n",
    "            'Poetry': 'Fiction',\n",
    "            'Biography & Autobiography': 'Nonfiction',\n",
    "            'History': 'Nonfiction',\n",
    "            'Literary Criticism': 'Nonfiction',\n",
    "            'Philosophy': 'Nonfiction',\n",
    "            'Religion': 'Nonfiction',\n",
    "            'Juvenile Nonfiction': \"Children's Nonfiction\",\n",
    "            'Science': 'Nonfiction'\n",
    "        }\n",
    "\n",
    "        # Apply mapping\n",
    "        mapped_categories = categories_series.map(category_mapping)\n",
    "\n",
    "        # Keep only valid (non-NaN) mapped categories and their indices\n",
    "        mapped_categories_clean = mapped_categories.dropna()\n",
    "        valid_indices = mapped_categories_clean.index\n",
    "\n",
    "        # Encode labels (keeps order consistent with mapped_categories_clean)\n",
    "        encoded_labels = self.label_encoder.fit_transform(mapped_categories_clean)\n",
    "\n",
    "        return mapped_categories_clean, encoded_labels, valid_indices\n",
    "\n",
    "    def train_ensemble(self, X, y):\n",
    "        \"\"\"Train an ensemble of models\"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # Train all models\n",
    "        trained_models = {}\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(X_train, y_train)\n",
    "            trained_models[name] = model\n",
    "\n",
    "            # Evaluate model\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Accuracy of {name}: {accuracy:.4f}\")\n",
    "\n",
    "        self.trained_models = trained_models\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def predict_ensemble(self, X):\n",
    "        \"\"\"Predict using majority voting across models\"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for name, model in self.trained_models.items():\n",
    "            pred = model.predict(X)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        # Majority vote\n",
    "        ensemble_pred = np.apply_along_axis(\n",
    "            lambda x: np.bincount(x).argmax(),\n",
    "            axis=0,\n",
    "            arr=np.array(predictions)\n",
    "        )\n",
    "\n",
    "        return self.label_encoder.inverse_transform(ensemble_pred)\n",
    "\n",
    "\n",
    "# Data preparation for training\n",
    "print(\"Preparing data...\")\n",
    "classifier = BookClassifier()\n",
    "\n",
    "# Filter books with known categories\n",
    "known_categories = books[books['categories'].notna()]\n",
    "\n",
    "# 🔥 NEW VERSION: Retrieve the 3 returned values\n",
    "mapped_categories_clean, encoded_labels, valid_indices = classifier.prepare_categories(known_categories['categories'])\n",
    "\n",
    "# 🔥 FIX: Use valid_indices for the features\n",
    "X_known = all_features.loc[valid_indices]\n",
    "y_known = encoded_labels\n",
    "\n",
    "print(f\"✅ Number of training examples: {len(X_known)}\")\n",
    "print(f\"✅ Class distribution: {Counter(mapped_categories_clean)}\")\n",
    "print(f\"✅ Check - X_known: {len(X_known)}, y_known: {len(y_known)}\")\n",
    "\n",
    "# Ensure the sizes match\n",
    "assert len(X_known) == len(y_known), f\"Inconsistent sizes: X={len(X_known)}, y={len(y_known)}\""
   ],
   "id": "6c8a416623e70756",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "✅ Number of training examples: 4606\n",
      "✅ Class distribution: Counter({'Fiction': 2828, 'Nonfiction': 1141, \"Children's Fiction\": 526, \"Children's Nonfiction\": 111})\n",
      "✅ Check - X_known: 4606, y_known: 4606\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:20:24.233446Z",
     "start_time": "2025-10-06T19:18:02.612361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the ensemble model\n",
    "print(\"Training the ensemble model...\")\n",
    "X_train, X_test, y_train, y_test = classifier.train_ensemble(X_known, y_known)\n",
    "\n",
    "# Detailed evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_ensemble = classifier.predict_ensemble(X_test)\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(\n",
    "    classifier.label_encoder.inverse_transform(y_test),\n",
    "    y_pred_ensemble\n",
    "))\n"
   ],
   "id": "c78b97f0a70dd307",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the ensemble model...\n",
      "Training random_forest...\n",
      "Accuracy of random_forest: 0.7408\n",
      "Training logistic_regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\PycharmProjects\\books__recommendations\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic_regression: 0.7223\n",
      "Training lightgbm...\n",
      "Accuracy of lightgbm: 0.7549\n",
      "\n",
      "Detailed classification report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "   Children's Fiction       0.54      0.69      0.60       105\n",
      "Children's Nonfiction       0.31      0.18      0.23        22\n",
      "              Fiction       0.83      0.80      0.81       566\n",
      "           Nonfiction       0.69      0.69      0.69       229\n",
      "\n",
      "             accuracy                           0.75       922\n",
      "            macro avg       0.59      0.59      0.58       922\n",
      "         weighted avg       0.75      0.75      0.75       922\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:21:03.977025Z",
     "start_time": "2025-10-06T19:20:59.980428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prediction for books without categories\n",
    "unknown_categories = books[books['categories'].isna()]\n",
    "if len(unknown_categories) > 0:\n",
    "    print(f\"Predicting categories for {len(unknown_categories)} books...\")\n",
    "\n",
    "    # Features for books without categories\n",
    "    X_unknown = all_features.loc[unknown_categories.index]\n",
    "\n",
    "    # Prediction\n",
    "    predicted_categories = classifier.predict_ensemble(X_unknown)\n",
    "\n",
    "    # Add predictions to the dataset\n",
    "    books.loc[unknown_categories.index, 'predicted_category'] = predicted_categories\n",
    "    books.loc[unknown_categories.index, 'category_source'] = 'predicted'\n",
    "else:\n",
    "    books['predicted_category'] = None\n",
    "    books['category_source'] = 'original'\n",
    "\n",
    "# Create the final category column\n",
    "# 🔥 CORRECTION : Create the final category column correctly\n",
    "\n",
    "# 1. First, apply the same category mapping we used in prepare_categories\n",
    "category_mapping = {\n",
    "    'Fiction': 'Fiction',\n",
    "    'Juvenile Fiction': \"Children's Fiction\",\n",
    "    'Comics & Graphic Novels': 'Fiction',\n",
    "    'Drama': 'Fiction',\n",
    "    'Poetry': 'Fiction',\n",
    "    'Biography & Autobiography': 'Nonfiction',\n",
    "    'History': 'Nonfiction',\n",
    "    'Literary Criticism': 'Nonfiction',\n",
    "    'Philosophy': 'Nonfiction',\n",
    "    'Religion': 'Nonfiction',\n",
    "    'Juvenile Nonfiction': \"Children's Nonfiction\",\n",
    "    'Science': 'Nonfiction'\n",
    "}\n",
    "\n",
    "# 2. Map the original categories using our mapping dictionary\n",
    "books['mapped_original_categories'] = books['categories'].map(category_mapping)\n",
    "\n",
    "# 3. Create final category: use mapped original categories where available, otherwise use predictions\n",
    "books['final_category'] = books['mapped_original_categories'].fillna(books['predicted_category'])\n",
    "\n",
    "# 4. Handle any remaining NaN values (safety net)\n",
    "books['final_category'] = books['final_category'].fillna('Unknown')\n",
    "\n",
    "# 5. Clean up temporary column\n",
    "books = books.drop('mapped_original_categories', axis=1)\n",
    "\n",
    "print(\"✅ Final category distribution:\")\n",
    "print(books['final_category'].value_counts())\n",
    "\n",
    "print(\"\\n✅ Category sources:\")\n",
    "print(books['category_source'].value_counts())"
   ],
   "id": "1dd90fcd157dc611",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting categories for 33 books...\n",
      "✅ Final category distribution:\n",
      "final_category\n",
      "Fiction                  2844\n",
      "Unknown                  1735\n",
      "Nonfiction               1151\n",
      "Children's Fiction        531\n",
      "Children's Nonfiction     113\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✅ Category sources:\n",
      "category_source\n",
      "predicted    33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:21:10.512917Z",
     "start_time": "2025-10-06T19:21:09.430079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the models\n",
    "joblib.dump(classifier, 'book_classifier_ensemble.pkl')\n",
    "joblib.dump(feature_engineer, 'feature_engineer.pkl')\n",
    "\n",
    "# Save the enriched dataset\n",
    "output_columns = [\n",
    "    'isbn13', 'title', 'authors', 'categories', 'final_category',\n",
    "    'category_source', 'description', 'published_year', 'average_rating',\n",
    "    'num_pages', 'ratings_count', 'thumbnail'\n",
    "]\n",
    "\n",
    "books[output_columns].to_csv(\"books_classified_enhanced.csv\", index=False)\n",
    "\n",
    "print(\"✅ Classification completed!\")\n",
    "print(f\"📊 Books classified: {len(books)}\")\n"
   ],
   "id": "b25e96fd06afae45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Classification completed!\n",
      "📊 Books classified: 6374\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:25:07.997044Z",
     "start_time": "2025-10-06T19:25:06.760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Colonnes à inclure dans le CSV final\n",
    "output_columns = books.columns.tolist()  # Toutes les colonnes originales\n",
    "if 'final_category' not in output_columns:\n",
    "    output_columns.append('final_category')  # Juste au cas où\n",
    "\n",
    "# Sauvegarde du nouveau dataset\n",
    "books[output_columns].to_csv(\"books_with_final_category.csv\", index=False)\n",
    "\n",
    "print(\"✅ New CSV created: 'books_with_final_category.csv'\")\n"
   ],
   "id": "fc1dad2e1884d105",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New CSV created: 'books_with_final_category.csv'\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:26:59.574145Z",
     "start_time": "2025-10-06T19:26:59.442756Z"
    }
   },
   "cell_type": "code",
   "source": "books.head()",
   "id": "11292ebae5ce4b32",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          isbn13      isbn10           title                          authors  \\\n",
       "0  9780002005883  0002005883          Gilead               Marilynne Robinson   \n",
       "1  9780002261982  0002261987    Spider's Web  Charles Osborne;Agatha Christie   \n",
       "2  9780006163831  0006163831    The One Tree             Stephen R. Donaldson   \n",
       "3  9780006178736  0006178731  Rage of angels                   Sidney Sheldon   \n",
       "4  9780006280897  0006280897  The Four Loves              Clive Staples Lewis   \n",
       "\n",
       "                      categories  \\\n",
       "0                        Fiction   \n",
       "1  Detective and mystery stories   \n",
       "2               American fiction   \n",
       "3                        Fiction   \n",
       "4                 Christian life   \n",
       "\n",
       "                                           thumbnail  \\\n",
       "0  http://books.google.com/books/content?id=KQZCP...   \n",
       "1  http://books.google.com/books/content?id=gA5GP...   \n",
       "2  http://books.google.com/books/content?id=OmQaw...   \n",
       "3  http://books.google.com/books/content?id=FKo2T...   \n",
       "4  http://books.google.com/books/content?id=XhQ5X...   \n",
       "\n",
       "                                         description  published_year  \\\n",
       "0  A NOVEL THAT READERS and critics have been eag...          2004.0   \n",
       "1  A new 'Christie for Christmas' -- a full-lengt...          2000.0   \n",
       "2  Volume Two of Stephen Donaldson's acclaimed se...          1982.0   \n",
       "3  A memorable, mesmerizing heroine Jennifer -- b...          1993.0   \n",
       "4  Lewis' work on the nature of love divides love...          2002.0   \n",
       "\n",
       "   average_rating  num_pages  ...     title_and_subtitle  \\\n",
       "0            3.85      247.0  ...                 Gilead   \n",
       "1            3.83      241.0  ...  Spider's Web: A Novel   \n",
       "2            3.97      479.0  ...           The One Tree   \n",
       "3            3.93      512.0  ...         Rage of angels   \n",
       "4            4.15      170.0  ...         The Four Loves   \n",
       "\n",
       "                                  tagged_description  \\\n",
       "0  9780002005883 A NOVEL THAT READERS and critics...   \n",
       "1  9780002261982 A new 'Christie for Christmas' -...   \n",
       "2  9780006163831 Volume Two of Stephen Donaldson'...   \n",
       "3  9780006178736 A memorable, mesmerizing heroine...   \n",
       "4  9780006280897 Lewis' work on the nature of lov...   \n",
       "\n",
       "                                 cleaned_description word_count  \\\n",
       "0  novel reader critic eagerly anticipating decad...      199.0   \n",
       "1  new christie christmas fulllength novel adapte...      205.0   \n",
       "2  volume two stephen donaldsons acclaimed second...       14.0   \n",
       "3  memorable mesmerizing heroine jennifer brillia...       57.0   \n",
       "4  lewis work nature love divide love four catego...       45.0   \n",
       "\n",
       "   avg_word_length  unique_words_ratio  sentence_count  predicted_category  \\\n",
       "0         4.804020            0.633166             7.0                 NaN   \n",
       "1         4.858537            0.682927             8.0                 NaN   \n",
       "2         6.857143            1.000000             1.0                 NaN   \n",
       "3         5.315789            0.877193             2.0                 NaN   \n",
       "4         5.577778            0.866667             3.0                 NaN   \n",
       "\n",
       "  category_source final_category  \n",
       "0             NaN        Fiction  \n",
       "1             NaN        Unknown  \n",
       "2             NaN        Unknown  \n",
       "3             NaN        Fiction  \n",
       "4             NaN        Unknown  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>...</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>unique_words_ratio</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>category_source</th>\n",
       "      <th>final_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9780002005883</td>\n",
       "      <td>0002005883</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>Marilynne Robinson</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=KQZCP...</td>\n",
       "      <td>A NOVEL THAT READERS and critics have been eag...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>247.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>9780002005883 A NOVEL THAT READERS and critics...</td>\n",
       "      <td>novel reader critic eagerly anticipating decad...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>4.804020</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9780002261982</td>\n",
       "      <td>0002261987</td>\n",
       "      <td>Spider's Web</td>\n",
       "      <td>Charles Osborne;Agatha Christie</td>\n",
       "      <td>Detective and mystery stories</td>\n",
       "      <td>http://books.google.com/books/content?id=gA5GP...</td>\n",
       "      <td>A new 'Christie for Christmas' -- a full-lengt...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>241.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Spider's Web: A Novel</td>\n",
       "      <td>9780002261982 A new 'Christie for Christmas' -...</td>\n",
       "      <td>new christie christmas fulllength novel adapte...</td>\n",
       "      <td>205.0</td>\n",
       "      <td>4.858537</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780006163831</td>\n",
       "      <td>0006163831</td>\n",
       "      <td>The One Tree</td>\n",
       "      <td>Stephen R. Donaldson</td>\n",
       "      <td>American fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=OmQaw...</td>\n",
       "      <td>Volume Two of Stephen Donaldson's acclaimed se...</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>479.0</td>\n",
       "      <td>...</td>\n",
       "      <td>The One Tree</td>\n",
       "      <td>9780006163831 Volume Two of Stephen Donaldson'...</td>\n",
       "      <td>volume two stephen donaldsons acclaimed second...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9780006178736</td>\n",
       "      <td>0006178731</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>Sidney Sheldon</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=FKo2T...</td>\n",
       "      <td>A memorable, mesmerizing heroine Jennifer -- b...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>512.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>9780006178736 A memorable, mesmerizing heroine...</td>\n",
       "      <td>memorable mesmerizing heroine jennifer brillia...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9780006280897</td>\n",
       "      <td>0006280897</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>Clive Staples Lewis</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=XhQ5X...</td>\n",
       "      <td>Lewis' work on the nature of love divides love...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>9780006280897 Lewis' work on the nature of lov...</td>\n",
       "      <td>lewis work nature love divide love four catego...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.577778</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:28:01.253363Z",
     "start_time": "2025-10-06T19:28:01.200040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "category_percent = books['final_category'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"✅ Distribution of final categories (%):\")\n",
    "print(category_percent)\n"
   ],
   "id": "782a5ebe7a6d926c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Distribution of final categories (%):\n",
      "final_category\n",
      "Fiction                  44.618764\n",
      "Unknown                  27.219956\n",
      "Nonfiction               18.057735\n",
      "Children's Fiction        8.330719\n",
      "Children's Nonfiction     1.772827\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ab65e2ee33e9854"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
